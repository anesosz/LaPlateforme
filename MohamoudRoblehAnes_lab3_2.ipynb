{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exZjZgYMzLvX"
   },
   "source": [
    "<img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://upload.wikimedia.org/wikipedia/fr/b/b1/Logo_EPF.png?raw=true\"> \n",
    "\n",
    "# Introduction to Machine Learning\n",
    "**P2024: Data engineering**<br>\n",
    "\n",
    "\n",
    "## Lab 3:  Dealing with imbalanced datasets\n",
    "\n",
    "### First name: Anes\n",
    "### Last name: MOHAMOUD ROBLEH \n",
    "### Group: DEA1\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c8c5c5f2f6bc7ab03bb842ddffdfb34ea87607c",
    "id": "fhtkCx8JxP-w"
   },
   "source": [
    "# Introduction\n",
    "Imbalanced classes are a common problem in machine learning classification where there are a disproportionate ratio of observations in each class.  Class imbalance can be found in many different areas including medical diagnosis, spam filtering, ad-click prediction and fraud detection.\n",
    "\n",
    "In this guide, we'll look at five possible ways to handle an imbalanced class problem using credit card data. <br>**Our objective will be to correctly classify fraudulent credit card transactions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "Hs7Gnj1yxP_d"
   },
   "outputs": [],
   "source": [
    "# useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "9c68ba8512d7c66d58927843c103d467e18597a1",
    "id": "EsmBS2smxP_f"
   },
   "outputs": [],
   "source": [
    "# setting up default plotting parameters\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20.0, 7.0]\n",
    "plt.rcParams.update({'font.size': 22,})\n",
    "\n",
    "sns.set_palette('viridis')\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk', font_scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "nMcX3gbwxP_f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28481, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59632.0</td>\n",
       "      <td>-0.365570</td>\n",
       "      <td>0.857326</td>\n",
       "      <td>1.601891</td>\n",
       "      <td>1.276523</td>\n",
       "      <td>0.265923</td>\n",
       "      <td>0.225669</td>\n",
       "      <td>0.456214</td>\n",
       "      <td>0.188240</td>\n",
       "      <td>-0.692619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087559</td>\n",
       "      <td>0.473280</td>\n",
       "      <td>-0.137397</td>\n",
       "      <td>0.244391</td>\n",
       "      <td>-0.272493</td>\n",
       "      <td>-0.283047</td>\n",
       "      <td>0.193123</td>\n",
       "      <td>0.143190</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62189.0</td>\n",
       "      <td>1.023773</td>\n",
       "      <td>-0.193395</td>\n",
       "      <td>1.276809</td>\n",
       "      <td>1.271923</td>\n",
       "      <td>-0.847045</td>\n",
       "      <td>0.411318</td>\n",
       "      <td>-0.720179</td>\n",
       "      <td>0.374841</td>\n",
       "      <td>0.878952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051391</td>\n",
       "      <td>0.273518</td>\n",
       "      <td>0.102789</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.152152</td>\n",
       "      <td>-0.372631</td>\n",
       "      <td>0.091121</td>\n",
       "      <td>0.035413</td>\n",
       "      <td>23.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75530.0</td>\n",
       "      <td>-0.997827</td>\n",
       "      <td>0.925281</td>\n",
       "      <td>0.616181</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>-0.025082</td>\n",
       "      <td>-0.828361</td>\n",
       "      <td>0.628374</td>\n",
       "      <td>0.276775</td>\n",
       "      <td>-0.991345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155928</td>\n",
       "      <td>0.328605</td>\n",
       "      <td>0.179409</td>\n",
       "      <td>0.351494</td>\n",
       "      <td>-0.285212</td>\n",
       "      <td>0.238287</td>\n",
       "      <td>-0.118637</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>42.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99940.0</td>\n",
       "      <td>-2.950527</td>\n",
       "      <td>-1.300757</td>\n",
       "      <td>1.421298</td>\n",
       "      <td>3.134102</td>\n",
       "      <td>4.604562</td>\n",
       "      <td>-1.773035</td>\n",
       "      <td>-0.561876</td>\n",
       "      <td>0.129093</td>\n",
       "      <td>-1.034959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397170</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>-0.201887</td>\n",
       "      <td>-0.371432</td>\n",
       "      <td>1.441045</td>\n",
       "      <td>0.293148</td>\n",
       "      <td>-0.188636</td>\n",
       "      <td>0.073548</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168047.0</td>\n",
       "      <td>2.089662</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>-2.295436</td>\n",
       "      <td>0.318867</td>\n",
       "      <td>0.781676</td>\n",
       "      <td>-0.648774</td>\n",
       "      <td>0.281364</td>\n",
       "      <td>-0.187433</td>\n",
       "      <td>0.576539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276488</td>\n",
       "      <td>-0.754165</td>\n",
       "      <td>0.155672</td>\n",
       "      <td>-0.082590</td>\n",
       "      <td>-0.027077</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>-0.042292</td>\n",
       "      <td>18.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   59632.0 -0.365570  0.857326  1.601891  1.276523  0.265923  0.225669   \n",
       "1   62189.0  1.023773 -0.193395  1.276809  1.271923 -0.847045  0.411318   \n",
       "2   75530.0 -0.997827  0.925281  0.616181  0.009446 -0.025082 -0.828361   \n",
       "3   99940.0 -2.950527 -1.300757  1.421298  3.134102  4.604562 -1.773035   \n",
       "4  168047.0  2.089662  0.064907 -2.295436  0.318867  0.781676 -0.648774   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.456214  0.188240 -0.692619  ...  0.087559  0.473280 -0.137397  0.244391   \n",
       "1 -0.720179  0.374841  0.878952  ...  0.051391  0.273518  0.102789  0.057612   \n",
       "2  0.628374  0.276775 -0.991345  ...  0.155928  0.328605  0.179409  0.351494   \n",
       "3 -0.561876  0.129093 -1.034959  ...  0.397170  0.443959 -0.201887 -0.371432   \n",
       "4  0.281364 -0.187433  0.576539  ... -0.276488 -0.754165  0.155672 -0.082590   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.272493 -0.283047  0.193123  0.143190    1.00      0  \n",
       "1  0.152152 -0.372631  0.091121  0.035413   23.42      0  \n",
       "2 -0.285212  0.238287 -0.118637  0.033654   42.81      0  \n",
       "3  1.441045  0.293148 -0.188636  0.073548    1.00      0  \n",
       "4 -0.027077  0.380547 -0.084189 -0.042292   18.79      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_csv('creditcard_sampled_10_percent.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlNpknjsGlMJ"
   },
   "source": [
    "**In the complete dataset, there are 492 fraudulent operations and 284315 valid operations.** <br>\n",
    "\n",
    "**However, during the lab, we will use a sampled dataset. You can however play with the real dataset afterwards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c7d92ecec94ee2633bd378b3d55100c6b9362636",
    "id": "t_f5PuXFxP_g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    28429\n",
      "1       52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "g = sns.countplot(data=df, x='Class', palette='viridis')\n",
    "g.set_xticklabels(['Not Fraud', 'Fraud'])\n",
    "\n",
    "def show_values_on_bars(ax):\n",
    "    for p in ax.patches:\n",
    "        _x = p.get_x() + p.get_width() / 2\n",
    "        _y = p.get_y() + p.get_height()\n",
    "        value = '{:.0f}'.format(p.get_height())\n",
    "        ax.text(_x, _y, value, ha=\"center\")\n",
    "\n",
    "show_values_on_bars(ax)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution of Transactions', fontsize=30)\n",
    "plt.xticks(fontsize=8)  # Adjust the font size of x-axis tick labels\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7zTapQwAdYV"
   },
   "source": [
    "**Exercise :** \n",
    "Compute the percentage of fraudulent transactions (ie: when Class == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a22d03aa7bf5b358cfbc7ca946f3367b98e9faa2",
    "id": "adCuZZcKxP_h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18257785892349285"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "No_Fraud = 28429\n",
    "Fraud = 52\n",
    "\n",
    "Total= No_Fraud + Fraud\n",
    "\n",
    "percentage_fraudulent = (Fraud / Total) * 100\n",
    "percentage_fraudulent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "460b8fbc891a865d755de263e832474d22718577",
    "id": "ss4_cT0wxP_i"
   },
   "source": [
    "From the plot above, we can see we have a very imbalanced class -  just 0.17% of our dataset belong to the target class!\n",
    "\n",
    "This is a problem because many machine learning models are designed to maximize overall accuracy, which especially with imbalanced classes may not be the best metric to use. Classification accuracy is defined as the number of correct predictions divided by total predictions times 100. For example, if we simply predicted all transactions are not fraud, we would get a classification acuracy score of over 99%!\n",
    "\n",
    "### Create Train and Test Sets\n",
    "\n",
    "The training set is used to build and validate the model, while the test set is reserved for testing the model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2zvIIV59eKS"
   },
   "source": [
    "**Exercise :** Separate the dataset into y and X. y being the traget column and X the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "876d7f98c708ae91ce22f728d63abdbb1c573fac",
    "id": "3LmbLWV2xP_i"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data for modeling\n",
    "# TODO: Code here\n",
    "y = df['Class']\n",
    "X = df.drop(columns=['Class'])\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5b635aecad2e3a59eee638e62194f02855f4f8f",
    "id": "Rn7VGjVnxP_j"
   },
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "537af7e533e55efc91ecda7a6f80b4c88bac39a1",
    "id": "gU1kpxXHxP_j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "# checking unique labels\n",
    "print('Unique predicted labels: ', (np.unique(dummy_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9_ofns04J_r"
   },
   "source": [
    "As we can see, our Dummy Classifier predicts target == 0 (No fraud) for all the test set. <br>\n",
    "\n",
    "**Exerice :** Compute the accuracy of the dummy classifier using two different ways :\n",
    "*   First with your own code (can be a loop or manipulation of numpy arrays)\n",
    "*   Then using `accuracy_score` from `sklearn.metrics`\n",
    "\n",
    "**Accuracy is the fraction of predictions our model got right. Formally, accuracy has the following definition:**\n",
    "$$ \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Number of total predictions}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YsJ_a1jm11z1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_with_code: 0.9985957028507232\n",
      "****************************************************\n",
      "accuracy score: 0.9985957028507232\n"
     ]
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "# TODO: accuracy with your own code\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "correct = np.sum(dummy_pred == y_test)\n",
    "total = len(y_test)\n",
    "accuracy_with_code = correct / total\n",
    "\n",
    "\n",
    "print('accuracy_with_code:', accuracy_with_code)\n",
    "print(52*'*')\n",
    "\n",
    "\n",
    "# TODO: accuracy with sklearn using sklearn.metrics.accuracy_score\n",
    "sklearn_accuracy = accuracy_score(y_test, dummy_pred)\n",
    "print('accuracy score:', sklearn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b3d37e60424e9bc6a0ffdf36bc667a7489ce186",
    "id": "CDyJzGYMxP_k"
   },
   "source": [
    "As predicted our accuracy score for classifying all transactions as not fraud is very high!  \n",
    "\n",
    "As the Dummy Classifier predicts only Class 0, it is clearly not a good option for our objective of correctly classifying fraudulent transactions.\n",
    "\n",
    "Let's see how logistic regression performs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "3326dfa795f14d1f4357881c3dde02f84b5574dd",
    "id": "BTl_w-oNxP_k"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Modeling the data as is\n",
    "# Train model\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    " \n",
    "# Predict on training set\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "df5a5a9588b0d0ee1d9b80e94d1c63885718976d",
    "id": "hgFdf8krxP_l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994382811402893"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "64afcae23af7b0903f10fa0d2992de3a137e2c10",
    "id": "SryXqYCfxP_l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    7115\n",
       "1       6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values\n",
    "predictions = pd.DataFrame(lr_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f50e9de7d0b21afebbdf41c36e30a3dd7e4204e0",
    "id": "dc2WyyyBxP_m"
   },
   "source": [
    "Logistic Regression outperformed the Dummy Classifier!  We can see that it predicted some instances of class 1, so this is definitely an improvement.  But can we do better?\n",
    "\n",
    "Let's see if we can apply some techniques for dealing with class imbalance to improve these results.\n",
    "\n",
    "## 1.  Change the performance metric\n",
    "Accuracy is not the best metric to use when evaluating imbalanced datasets as it can be misleading.  Metrics that can provide better insight include:\n",
    " - **Confusion Matrix:**  a talbe showing correct predictions and types of incorrect predictions.\n",
    " - **Precision:**  the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier's exactness. Low precision indicates a high number of false positives.\n",
    " - **Recall:**  the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier's completeness. Low recall indicates a high number of false negatives.\n",
    " - **F1: Score:**  the weighted average of precision and recall.\n",
    " \n",
    "Since our main objective with the dataset is to prioritize accuraltely classifying fraud cases the recall score can be considered our main metric to use for evaluating outcomes.<br>\n",
    "\n",
    "**How do we compute these metrics :**\n",
    "Let's code these metrics ourselves to make sure we understand what it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgB9bxRFoPjw"
   },
   "source": [
    "**Exercise :** For the LogisticRegression model, compute true positives (`tp`), false positives (`fp`), false negatives (`fn`), true negatives (`tn`). You can find the formal definitions here https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True Positives (tp): Correctly predicted positive cases (fraudulent transactions correctly identified).\n",
    "- False Positives (fp): Incorrectly predicted positive cases (non-fraudulent transactions incorrectly identified as fraudulent).\n",
    "- False Negatives (fn): Incorrectly predicted negative cases (fraudulent transactions incorrectly identified as non-fraudulent).\n",
    "- True Negatives (tn): Correctly predicted negative cases (non-fraudulent transactions correctly identified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p0fcMfq7oS1C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (tp): 6\n",
      "False Positives (fp): 0\n",
      "False Negatives (fn): 4\n",
      "True Negatives (tn): 7111\n"
     ]
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "import numpy as np\n",
    "\n",
    "# Confusion matrix elements\n",
    "tp = np.sum((lr_pred == 1) & (y_test == 1))\n",
    "fp = np.sum((lr_pred == 1) & (y_test == 0))\n",
    "fn = np.sum((lr_pred == 0) & (y_test == 1))\n",
    "tn = np.sum((lr_pred == 0) & (y_test == 0))\n",
    "\n",
    "print('True Positives (tp):' ,tp)\n",
    "print('False Positives (fp):',fp)\n",
    "print('False Negatives (fn):',fn)\n",
    "print('True Negatives (tn):' ,tn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEoO62VoocZQ"
   },
   "source": [
    "**Exercise :** Compute the metrics `Precision`, `Recall` and `f1-score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iXksWfoYodwk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.6\n",
      "F1-score: 0.7499999999999999\n"
     ]
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "# Precision\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "# Recall\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "# F1-score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('F1-score:', f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jE-TlVmCokdM"
   },
   "source": [
    "**How do we compute these metrics using sklearn:**\n",
    "Let's see how we compute these metrics using `sklearn.metrics`. We'll do it for the `LogisticRegression`. We need `y_test` which are the real test observations and we need `lr_pred` which are the predictions of the `LogisticRegression` on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AwByqtYzCWNR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9994382811402893\n",
      "F1-score is  0.75\n",
      "Recall is  0.6\n",
      "Confusion matrix is \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "0  7111  0\n",
       "1     4  6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score\n",
    "\n",
    "# Example on LogisticRegression\n",
    "print('Accuracy is ', accuracy_score(y_test, lr_pred))\n",
    "print('F1-score is ', f1_score(y_test, lr_pred))\n",
    "print('Recall is ', recall_score(y_test, lr_pred))\n",
    "print('Confusion matrix is ')\n",
    "pd.DataFrame(confusion_matrix(y_test, lr_pred)).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dffefb9a7656b70369b1392747345f1b7c5ad830",
    "collapsed": true,
    "id": "4dg1h9pXxP_o"
   },
   "source": [
    "We have a very high accuracy score of 0.999 but a F1 score of only 0.752.  And from the confusion matrix, we can see we are misclassifying several observations leading to a recall score of only 0.64.\n",
    "\n",
    "## 2. Change the algorithm\n",
    "While in every machine learning problem, its a good rule of thumb to try a variety of algorithms, it can be especially beneficial with imbalanced datasets.  Decision trees frequently perform well on imbalanced data.  They work by learning a hierachy of if/else questions.  This can force both classes to be addressed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgUnnmxkD-G7"
   },
   "source": [
    "**Exercise** Use a `RandomForestClassifier` with `n_estimators=10` and compute the usual metrics (accuracy, f1-score, recall and confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "aa114a52def766752d99bdbb8798926b08bfa7c0",
    "id": "nLMJvCi0xP_o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (tp): 7\n",
      "False Positives (fp): 0\n",
      "False Negatives (fn): 3\n",
      "True Negatives (tn): 7111\n"
     ]
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Train the RandomForestClassifier model\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#  Predictions on the test set\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# Confusion matrix elements\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, rf_pred).ravel()\n",
    "\n",
    "print('True Positives (tp):' ,tp)\n",
    "print('False Positives (fp):',fp)\n",
    "print('False Negatives (fn):',fn)\n",
    "print('True Negatives (tn):' ,tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.999578710855217\n",
      "F1-score is  0.8235294117647058\n",
      "Recall is  0.7\n",
      "Confusion matrix is \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "0  7111  0\n",
       "1     3  7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy, Recall, F1-score, and Accuracy\n",
    "print('Accuracy is ', accuracy_score(y_test, rf_pred))\n",
    "print('F1-score is ', f1_score(y_test, rf_pred))\n",
    "print('Recall is ', recall_score(y_test, rf_pred))\n",
    "print('Confusion matrix is ')\n",
    "pd.DataFrame(confusion_matrix(y_test, rf_pred)).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adead2ec74b7016ebc547ee60e0b44dc1189a2a4",
    "id": "3JhZb-LLxP_q"
   },
   "source": [
    "# Resampling Techniques\n",
    "\n",
    "## 3. Oversampling Minority Class\n",
    "Oversampling can be defined as adding more copies of the minority class.  Oversampling can be a good choice when you don't have a ton of data to work with.  A con to consider when undersampling is that it can cause overfitting and poor generalization to your test set.\n",
    "\n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class.\n",
    "\n",
    "### **Important Note**\n",
    "Always split into test and train sets BEFORE trying any resampling techniques!  Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets!  This can allow our model to simply memorize specific data points and cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "e48e7eb85c4b0a67c3f096726fef7b472e6b293d",
    "id": "X3cfMhP3xP_q"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "8d7567a5b4ebc92b3aaff6236f2253d969488993",
    "id": "rPbkitvmxP_r"
   },
   "outputs": [],
   "source": [
    "# Separate input features and target\n",
    "y = df['Class']\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "523a5c12eb7520127ba53231e3872a21b3101ce7",
    "id": "_dgyN9KQxP_r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>132230.0</td>\n",
       "      <td>1.797014</td>\n",
       "      <td>-0.620617</td>\n",
       "      <td>-3.089936</td>\n",
       "      <td>0.195394</td>\n",
       "      <td>0.903350</td>\n",
       "      <td>-1.025187</td>\n",
       "      <td>1.135037</td>\n",
       "      <td>-0.538027</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319507</td>\n",
       "      <td>0.526784</td>\n",
       "      <td>-0.393472</td>\n",
       "      <td>0.177619</td>\n",
       "      <td>0.606809</td>\n",
       "      <td>1.006654</td>\n",
       "      <td>-0.201444</td>\n",
       "      <td>-0.062785</td>\n",
       "      <td>219.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13708</th>\n",
       "      <td>36203.0</td>\n",
       "      <td>1.127534</td>\n",
       "      <td>-1.743518</td>\n",
       "      <td>-0.007402</td>\n",
       "      <td>-2.623771</td>\n",
       "      <td>-1.333444</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>-0.772654</td>\n",
       "      <td>-0.052193</td>\n",
       "      <td>1.656981</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497790</td>\n",
       "      <td>-0.917727</td>\n",
       "      <td>-0.304940</td>\n",
       "      <td>-0.993739</td>\n",
       "      <td>0.632809</td>\n",
       "      <td>-0.770682</td>\n",
       "      <td>0.102616</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>185.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27219</th>\n",
       "      <td>936.0</td>\n",
       "      <td>-1.331879</td>\n",
       "      <td>1.621242</td>\n",
       "      <td>0.590870</td>\n",
       "      <td>1.333507</td>\n",
       "      <td>-0.574223</td>\n",
       "      <td>-0.108092</td>\n",
       "      <td>-0.214766</td>\n",
       "      <td>1.040828</td>\n",
       "      <td>-0.257084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.124593</td>\n",
       "      <td>-0.048547</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>-0.037439</td>\n",
       "      <td>-0.210650</td>\n",
       "      <td>0.285472</td>\n",
       "      <td>0.124636</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10573</th>\n",
       "      <td>114587.0</td>\n",
       "      <td>1.628844</td>\n",
       "      <td>-1.065076</td>\n",
       "      <td>-0.497869</td>\n",
       "      <td>0.159299</td>\n",
       "      <td>-1.157159</td>\n",
       "      <td>-1.072094</td>\n",
       "      <td>-0.130069</td>\n",
       "      <td>-0.215774</td>\n",
       "      <td>1.148935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311983</td>\n",
       "      <td>-1.179808</td>\n",
       "      <td>0.393706</td>\n",
       "      <td>0.482117</td>\n",
       "      <td>-0.893336</td>\n",
       "      <td>0.716274</td>\n",
       "      <td>-0.126618</td>\n",
       "      <td>-0.018556</td>\n",
       "      <td>200.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>43872.0</td>\n",
       "      <td>1.254027</td>\n",
       "      <td>-0.792932</td>\n",
       "      <td>0.242420</td>\n",
       "      <td>-0.446319</td>\n",
       "      <td>-0.940256</td>\n",
       "      <td>-0.424515</td>\n",
       "      <td>-0.499335</td>\n",
       "      <td>-0.050957</td>\n",
       "      <td>-0.423494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105934</td>\n",
       "      <td>0.292283</td>\n",
       "      <td>-0.115116</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.571071</td>\n",
       "      <td>-0.119523</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>0.013177</td>\n",
       "      <td>64.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time        V1        V2        V3        V4        V5        V6  \\\n",
       "7323   132230.0  1.797014 -0.620617 -3.089936  0.195394  0.903350 -1.025187   \n",
       "13708   36203.0  1.127534 -1.743518 -0.007402 -2.623771 -1.333444 -0.011875   \n",
       "27219     936.0 -1.331879  1.621242  0.590870  1.333507 -0.574223 -0.108092   \n",
       "10573  114587.0  1.628844 -1.065076 -0.497869  0.159299 -1.157159 -1.072094   \n",
       "4755    43872.0  1.254027 -0.792932  0.242420 -0.446319 -0.940256 -0.424515   \n",
       "\n",
       "             V7        V8        V9  ...       V21       V22       V23  \\\n",
       "7323   1.135037 -0.538027  0.093220  ...  0.319507  0.526784 -0.393472   \n",
       "13708 -0.772654 -0.052193  1.656981  ... -0.497790 -0.917727 -0.304940   \n",
       "27219 -0.214766  1.040828 -0.257084  ...  0.002048  0.124593 -0.048547   \n",
       "10573 -0.130069 -0.215774  1.148935  ... -0.311983 -1.179808  0.393706   \n",
       "4755  -0.499335 -0.050957 -0.423494  ...  0.105934  0.292283 -0.115116   \n",
       "\n",
       "            V24       V25       V26       V27       V28  Amount  Class  \n",
       "7323   0.177619  0.606809  1.006654 -0.201444 -0.062785  219.00      0  \n",
       "13708 -0.993739  0.632809 -0.770682  0.102616  0.054434  185.41      0  \n",
       "27219  0.063000 -0.037439 -0.210650  0.285472  0.124636    5.99      0  \n",
       "10573  0.482117 -0.893336  0.716274 -0.126618 -0.018556  200.53      0  \n",
       "4755   0.101954  0.571071 -0.119523  0.007714  0.013177   64.96      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "fd10e5f5f96a9c3fe607d0fb35475fe62fa75675",
    "id": "iFrbRmKrxP_r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    21318\n",
       "1    21318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate minority and majority classes\n",
    "not_fraud = X[X.Class==0]\n",
    "fraud = X[X.Class==1]\n",
    "\n",
    "# upsample minority\n",
    "fraud_upsampled = resample(fraud,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=27) # reproductible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.Class.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrQdVcqwEndH"
   },
   "source": [
    "**Exercise** Train a model (`LogisticRegression` for example) on the `upsampled` data and compute the usual metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "48e16be49fbda450115a2d169d3edc5979f633c0",
    "id": "gCYT6bqfxP_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (tp_up): 6945\n",
      "False Positives (fp_up): 166\n",
      "False Negatives (fn_up): 0\n",
      "True Negatives (tn_up): 10\n",
      "Accuracy is  0.9766886673220053\n",
      "F1-score is  0.10752688172043011\n",
      "Recall is  1.0\n",
      "Confusion matrix is \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6945</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  6945  166\n",
       "1     0   10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y) for upsampled data\n",
    "y_upsampled = upsampled['Class']\n",
    "X_upsampled = upsampled.drop('Class', axis=1)\n",
    "\n",
    "\n",
    "# Split the upsampled data into training and testing sets\n",
    "X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "# Make predictions on the original test set\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "# Confusion matrix elements\n",
    "tp_up,fp_up,fn_up,tn_up, = confusion_matrix(y_test, lr_pred).ravel()\n",
    "\n",
    "\n",
    "print('True Positives (tp_up):' ,tp_up)\n",
    "print('False Positives (fp_up):',fp_up)\n",
    "print('False Negatives (fn_up):',fn_up)\n",
    "print('True Negatives (tn_up):' ,tn_up)\n",
    "\n",
    "# Accuracy, Recall, F1-score, and Accuracy\n",
    "print('Accuracy is ', accuracy_score(y_test, lr_pred))\n",
    "print('F1-score is ', f1_score(y_test, lr_pred))\n",
    "print('Recall is ', recall_score(y_test, lr_pred))\n",
    "print('Confusion matrix is ')\n",
    "pd.DataFrame(confusion_matrix(y_test, lr_pred)).head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upbO-79QE_QO"
   },
   "source": [
    "**Exercise** Compare the results with what we have seen before\n",
    "\n",
    "**Answer here**  \n",
    "- `Before Upsampling`: The model had a very high accuracy `0.9992`, but it was not performing well in terms of identifying the minority class (fraudulent transactions), `low recall score: 0.5`\n",
    "- `After upsampling`: The accuracy decreased slightly `0.9767`, but the model correctly identified fraudulent transactions. `The recall score improuved: 1.0`. The F1 score droped from `0.625` to `0.108`: `more false positives`(1 to 166).\n",
    "\n",
    "So as the model becomes more sensitive to the minority class, this leads to a trade-off: while recall improves, accuracy decrease.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0b5c7e2b673baac682bb89d9484ad9f7fbea16e",
    "id": "hFwlmb2vxP_w"
   },
   "source": [
    "## 4. Undersampling Majority Class\n",
    "Undersampling can be defined as removing some observations of the majority class.  Undersampling can be a good choice when you have a ton of data -think millions of rows.  But a drawback to undersampling is that we are removing information that may be valuable.\n",
    "\n",
    "We will again use the resampling module from Scikit-Learn to randomly remove samples from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "15c289c9551acca877a3ca824c6b2f074daccce6",
    "id": "nlsZg-7rxP_w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    42\n",
       "1    42\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still using our separated classes fraud and not_fraud from above\n",
    "\n",
    "# downsample majority\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
    "\n",
    "# checking counts\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Thci1idnFPHI"
   },
   "source": [
    "**Exercise** Train a model (`LogisticRegression` for example) on the `downsampled` data and compute the usual metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "339ff5f558175b8daf2a4536d4749978e7e7c4fd",
    "id": "59RtcXp7xP_x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (tp_down): 6631\n",
      "False Positives (fp_down): 480\n",
      "False Negatives (fn_down): 0\n",
      "True Negatives (tn_down): 10\n",
      "Accuracy is  0.9325937368347142\n",
      "F1-score is  0.04\n",
      "Recall is  1.0\n",
      "Confusion matrix is \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6631</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  6631  480\n",
       "1     0   10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "\n",
    "y_downsampled = downsampled['Class']\n",
    "X_downsampled = downsampled.drop('Class', axis=1)\n",
    "\n",
    "X_train_downsampled, X_test_downsampled, y_train_downsampled, y_test_downsampled = train_test_split(X_downsampled, y_downsampled, test_size=0.25, random_state=27)\n",
    "\n",
    "# Train the LogisticRegression model on the downsampled training set\n",
    "lr = LogisticRegression().fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "# Make predictions on the original test set\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix elements\n",
    "tp_down, fp_down, fn_down, tn_down = confusion_matrix(y_test, lr_pred).ravel()\n",
    "\n",
    "\n",
    "print('True Positives (tp_down):' ,tp_down)\n",
    "print('False Positives (fp_down):',fp_down)\n",
    "print('False Negatives (fn_down):',fn_down)\n",
    "print('True Negatives (tn_down):' ,tn_down)\n",
    "\n",
    "\n",
    "# Accuracy, Recall, F1-score, and Accuracy\n",
    "print('Accuracy is ', accuracy_score(y_test, lr_pred))\n",
    "print('F1-score is ', f1_score(y_test, lr_pred))\n",
    "print('Recall is ', recall_score(y_test, lr_pred))\n",
    "print('Confusion matrix is ')\n",
    "pd.DataFrame(confusion_matrix(y_test, lr_pred)).head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7t3cNm0IrGA"
   },
   "source": [
    "**Exercise** Compare the results with what we have seen before\n",
    "\n",
    "- `Recall:`\n",
    "Both methods achieved a perfect recall of 100%, meaning all fraudulent transactions were correctly identified.\n",
    "\n",
    "- `Accuracy:`\n",
    "The accuracy for the upsampling method was higher `(97.67%)` compared to the undersampling method `(93.26%)`. This shows that the upsampling method was better at correctly classifying both fraudulent and non-fraudulent transactions.\n",
    "\n",
    "- `F1-score:`\n",
    "The F1-score is lower for the undersampling method `(0.04)` compared to the upsampling method `(0.108)`. This is due to the higher number of false positives in the undersampling method.\n",
    "\n",
    "So we balanced the dataset by upsampling fraud cases, which proved more successful than downsampling non-fraud cases in achieving better balance between recall and accuracy for this dataset, resulting in superior overall performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ce5844e2d4447485416cf927112a8c2cf3fd1d8",
    "id": "8EsperTjxP_z"
   },
   "source": [
    "## 5. Generate Synthetic Samples\n",
    "SMOTE or Synthetic Minority Oversampling Technique is a popular algorithm to creates sythetic observations of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "5d01357038bb94f8a93c77141e462153c73c5ab8",
    "id": "EvPcxIOPxP_0"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "sm = SMOTE(random_state=27, sampling_strategy=1.0)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "669cb81d0cf57aa6c3769a586253ac5e1e5622bf",
    "id": "Kzxu12czxP_0"
   },
   "outputs": [],
   "source": [
    "smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "smote_pred = smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2uObe32IXRG"
   },
   "source": [
    "**Exercise** Compute metrics for these predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (tp_down): 7019\n",
      "False Positives (fp_down): 92\n",
      "False Negatives (fn_down): 1\n",
      "True Negatives (tn_down): 9\n",
      "Accuracy is  0.9869400365117259\n",
      "F1-score is  0.16216216216216217\n",
      "Recall is  0.9\n",
      "Confusion matrix is \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7019</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1\n",
       "0  7019  92\n",
       "1     1   9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Compute confusion matrix elements\n",
    "tp_smote, fp_smote, fn_smote, tn_smote = confusion_matrix(y_test, smote_pred).ravel()\n",
    "\n",
    "\n",
    "print('True Positives (tp_down):' ,tp_smote)\n",
    "print('False Positives (fp_down):',fp_smote)\n",
    "print('False Negatives (fn_down):',fn_smote)\n",
    "print('True Negatives (tn_down):' ,tn_smote)\n",
    "\n",
    "\n",
    "# Accuracy, Recall, F1-score, and Accuracy\n",
    "print('Accuracy is ', accuracy_score(y_test, smote_pred))\n",
    "print('F1-score is ', f1_score(y_test, smote_pred))\n",
    "print('Recall is ', recall_score(y_test, smote_pred))\n",
    "print('Confusion matrix is ')\n",
    "pd.DataFrame(confusion_matrix(y_test, smote_pred)).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bde53447fef057292a1d52b62978e53b7d44f8f",
    "id": "xIjJZL_nxP_1"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We covered 5 different methods for dealing with imbalanced datasets:\n",
    "1.  Change the performance metric\n",
    "2.  Oversampling minority class\n",
    "3.  Undersampling majority class\n",
    "4.  Change the algorithm\n",
    "5.  Generate synthetic samples\n",
    "\n",
    "These are just some of the many possible methods to try when dealing with imbalanced datasets, and not an exhaustive list.  Some others methods to consider are collecting more data or choosing different resampling ratios - you don't have to have exactly a 1:1 ratio!  You should always try several approaches and then decide which is best for your problem."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lab3_Imbalanced_datasets_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
